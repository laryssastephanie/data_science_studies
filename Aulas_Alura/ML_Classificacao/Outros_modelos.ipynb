{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('busca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = df.iloc[:, :3]\n",
    "Y_df = df['comprou']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdummies_df = pd.get_dummies(X_df)\n",
    "Ydummies_df = Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xdummies_df.values\n",
    "Y = Ydummies_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagem_treino = 0.8\n",
    "porcentagem_teste = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho_treino = int(porcentagem_treino * len(Y))\n",
    "tamanho_teste = int(porcentagem_teste * len(Y))\n",
    "tamanho_validacao = len(Y) - tamanho_teste - tamanho_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_dados = X[:tamanho_treino]\n",
    "treino_marcacoes = Y[:tamanho_treino]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "fim_de_teste = tamanho_treino + tamanho_teste\n",
    "teste_dados = X[tamanho_treino:fim_de_teste]\n",
    "teste_marcacoes = Y[tamanho_treino:fim_de_teste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacao_dados = X[fim_de_teste:]\n",
    "validacao_marcacoes = Y[fim_de_teste:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treinando o modelo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes):\n",
    "    modelo.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "    resultado = modelo.predict(teste_dados)\n",
    "    acertos = (resultado == teste_marcacoes)\n",
    "\n",
    "    total_acertos = sum(acertos)\n",
    "    total_elementos = len(teste_dados)\n",
    "    taxa_acerto = 100  * total_acertos / total_elementos\n",
    "    msg = \"Taxa de Acerto do {0}: {1}\".format(nome, taxa_acerto)\n",
    "    print(msg)\n",
    "    return taxa_acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de Acerto do AdaBoost: 84.0\n"
     ]
    }
   ],
   "source": [
    "modelo_adab = AdaBoostClassifier()\n",
    "resultado_adab = fit_and_predict(\"AdaBoost\", modelo_adab, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de Acerto do MultinomialNB: 82.0\n"
     ]
    }
   ],
   "source": [
    "modelo_multi = MultinomialNB()\n",
    "resultado_multi = fit_and_predict(\"MultinomialNB\", modelo_multi, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resultado_multi > resultado_adab:\n",
    "    vencedor = modelo_multi\n",
    "else:\n",
    "    vencedor = modelo_adab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de Acerto do vencedor no mundo real: 85.0\n"
     ]
    }
   ],
   "source": [
    "resultado = vencedor.predict(validacao_dados)\n",
    "acertos = (resultado == validacao_marcacoes)\n",
    "\n",
    "total_acertos = sum(acertos)\n",
    "total_elementos = len(validacao_marcacoes)\n",
    "taxa_acerto = 100  * total_acertos / total_elementos\n",
    "msg = \"Taxa de Acerto do vencedor no mundo real: {0}\".format(taxa_acerto)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 18, 1: 82})"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(teste_marcacoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de acerto base: 82.000000\n"
     ]
    }
   ],
   "source": [
    "acerto_base = max(Counter(validacao_marcacoes).values())\n",
    "taxa_de_acerto_base = 100.0 * acerto_base / len(validacao_marcacoes)\n",
    "print(\"Taxa de acerto base: %f\" % taxa_de_acerto_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de teste: 100\n"
     ]
    }
   ],
   "source": [
    "total_de_elementos = len(validacao_dados)\n",
    "print(\"Total de teste: %d\" % total_de_elementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d97a3dbca231d9020d4cca2fd426dfd394f300c675eea7ed921aca4ffa7b18a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
